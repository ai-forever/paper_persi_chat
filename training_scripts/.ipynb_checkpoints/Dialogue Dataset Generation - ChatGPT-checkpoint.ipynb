{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dialogue(text, summary, num_turns=3):\n",
    "    messages_bot = [\n",
    "        {\"role\": \"system\", \"content\": \"You should briefly answer the questions on the following text. If there is no answer in the given text, then you must answer that there is not enough information. Your answers should be brief. \\n\" + text},\n",
    "    ]\n",
    "    \n",
    "    messages_person = [\n",
    "        {\"role\": \"system\", \"content\": \"You should be asking short questions about an article you can't see. You only see the following summary. Your task is to ask clarifying dependent questions in order to understand the source text. You can ask only single short question at each turn. \\n\" + summary},\n",
    "    ]\n",
    "    \n",
    "    dialogue = []\n",
    "    for turn in range(num_turns):\n",
    "        \n",
    "        try:\n",
    "    \n",
    "            question = openai.ChatCompletion.create(\n",
    "              model=\"gpt-3.5-turbo\",\n",
    "              messages = messages_person,\n",
    "              temperature=0.7,\n",
    "              max_tokens=512,\n",
    "              top_p=1,\n",
    "              frequency_penalty=0,\n",
    "              presence_penalty=0\n",
    "            )\n",
    "            question = question['choices'][0]['message']\n",
    "\n",
    "            messages_person.append(question)\n",
    "            messages_bot.append({'role': 'user', 'content': question['content'].strip()})\n",
    "\n",
    "\n",
    "            response = openai.ChatCompletion.create(\n",
    "              model=\"gpt-3.5-turbo\",\n",
    "              messages = messages_bot,\n",
    "              temperature=0.7,\n",
    "              max_tokens=512,\n",
    "              top_p=1,\n",
    "              frequency_penalty=0,\n",
    "              presence_penalty=0\n",
    "            )\n",
    "\n",
    "            response = response['choices'][0]['message']\n",
    "\n",
    "            messages_bot.append(response)\n",
    "            messages_person.append({'role': 'user', 'content': response['content'].strip()})\n",
    "\n",
    "            dialogue.append((question['content'].strip(), response['content'].strip()))\n",
    "        \n",
    "        except Exception as e:\n",
    "            if len(dialogue) >= 2:\n",
    "                return dialogue\n",
    "            \n",
    "            raise Exception('short dialogue') from e\n",
    "        \n",
    "    return dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_scripts.summary_generation_inference import BartGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = BartGenerator(\"/home/jovyan/chatbot/_common/bart_summarization/distilbart-cnn-12-6_1e-5\",\n",
    "                            device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_segments(raw_segments, max_len=4000):\n",
    "    '''\n",
    "    Join paper segments\n",
    "    '''\n",
    "    \n",
    "    indeces_sections = [[0,1]]\n",
    "    \n",
    "    prev_title = raw_segments[2][-1]\n",
    "    i = 2\n",
    "    cur_section = []\n",
    "    while i < len(raw_segments):\n",
    "        cur_title = raw_segments[i][-1]\n",
    "        if cur_title == prev_title:\n",
    "            cur_section.append(i)\n",
    "        else:\n",
    "            indeces_sections.append(cur_section)\n",
    "            cur_section = [i]\n",
    "            prev_title = cur_title\n",
    "        i += 1\n",
    "    \n",
    "    if len(cur_section) > 0:\n",
    "        indeces_sections.append(cur_section)\n",
    "    \n",
    "    joined_segments = []\n",
    "    for sec in indeces_sections:\n",
    "        cur_text = ''\n",
    "        cur_split = []\n",
    "        \n",
    "        for idx in sec:\n",
    "            if len(cur_text + '\\n' + raw_segments[idx][1]) < max_len or len(cur_text) == 0:\n",
    "                cur_split.append({'id': raw_segments[idx][0],\n",
    "                                  'title': raw_segments[idx][-2], 'section_type': raw_segments[idx][-1]})\n",
    "                cur_text = cur_text + '\\n' + raw_segments[idx][1]\n",
    "                cur_text = cur_text.strip()\n",
    "            \n",
    "            else:\n",
    "                joined_segments.append((cur_text, cur_split))\n",
    "                cur_text = ''\n",
    "                cur_split = []\n",
    "        \n",
    "        if len(cur_text) > 0:\n",
    "            joined_segments.append((cur_text, cur_split))\n",
    "                \n",
    "    return joined_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../_common/papers_segmented_data/segmented_papers-2.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing cycle over all papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../_common/papers_segmented_data/davinci_dialogues_full_v2.pkl', 'rb') as f:\n",
    "    davinci_dialogues = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../_common/papers_segmented_data/chatgpt_dialogues_full.pkl', 'rb') as f:\n",
    "    chatgpt_dialogues = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_papers = set([d['meta_paper']['paper_id'] for d in davinci_dialogues]) | \\\n",
    "                     set([d['meta_paper']['paper_id'] for d in chatgpt_dialogues])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 2254/5000 [9:26:14<10:44:02, 14.07s/it]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(15000, 20000)):\n",
    "    if data[i]['paper_id'] in processed_papers:\n",
    "        continue\n",
    "        \n",
    "    processed_papers.add(data[i]['paper_id'])\n",
    "    \n",
    "    segmented_paper = join_segments(data[i]['segments'])\n",
    "    \n",
    "    #  select random segment\n",
    "    j = random.randint(0, len(segmented_paper) - 1)\n",
    "    random_segment = segmented_paper[j]\n",
    "    \n",
    "    # skip acknowledgements\n",
    "    if random_segment[1][-1]['section_type'].startswith('acknowledgement'):\n",
    "        continue\n",
    "    \n",
    "    # filter short\n",
    "    if len(random_segment[0]) < 1500:\n",
    "        continue\n",
    "        \n",
    "    with open('logs/processed.txt', 'a') as f:\n",
    "        f.write(f'Processing {i}\\n')\n",
    "        \n",
    "    try:\n",
    "        text = random_segment[0]\n",
    "        summary = summarizer(text)[0]\n",
    "        with open('logs/processed.txt', 'a') as f:\n",
    "            f.write(f'Generating dialog for {i}...\\n')\n",
    "        result = generate_dialogue(text, summary, num_turns=4)\n",
    "    except Exception as e:\n",
    "        with open('logs/processed.txt', 'a') as f:\n",
    "            f.write(f'Error for {i}: {str(e)}\\n')\n",
    "        continue\n",
    "    \n",
    "    chatgpt_dialogues.append({\n",
    "        'text': random_segment[0],\n",
    "        'dialogue': result,\n",
    "        'meta_segments': random_segment[1],\n",
    "        'meta_paper': {'title': data[i]['title'], 'paper_id': data[i]['paper_id']},\n",
    "        'used_summary': summary,\n",
    "    })\n",
    "    \n",
    "    with open('../_common/papers_segmented_data/chatgpt_dialogues_full_upd.pkl', 'wb') as f:\n",
    "        pickle.dump(chatgpt_dialogues, f)\n",
    "        \n",
    "    with open('../_common/papers_segmented_data/chatgpt_dialogues_full_copy_upd.pkl', 'wb') as f:\n",
    "        pickle.dump(chatgpt_dialogues, f)\n",
    "        \n",
    "    with open('logs/processed.txt', 'a') as f:\n",
    "        f.write(f'Saved for {i}, segments {j}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chatgpt_dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chatgpt_dialogues[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialogue in chatgpt_dialogues:\n",
    "    turns = []\n",
    "    for turn in dialogue['dialogue']:\n",
    "        turns.append({'speaker': 'person', 'text': turn[0]})\n",
    "        turns.append({'speaker': 'bot', 'text': turn[1]})\n",
    "    dialogue['parsed_dialogue'] = {\n",
    "        'summary': dialogue['used_summary'],\n",
    "        'turns': turns\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../_common/papers_segmented_data/chatgpt_dialogues_full_postproc_upd.pkl', 'wb') as f:\n",
    "    pickle.dump(chatgpt_dialogues, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
