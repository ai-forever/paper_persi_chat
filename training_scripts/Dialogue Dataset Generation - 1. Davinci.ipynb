{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802b91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5be3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4311a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_start = '''Generate a dialogue between you and another person based on the following paper. You have access to the paper. In the first utterance you should write a short summary. The other person sees only your summary and asks four (4) questions, separated by your answers.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39446e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def davinci_complete(text):\n",
    "    \n",
    "    prompt = prompt_start + '\\n\\n' + text\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt,\n",
    "      temperature=0.7,\n",
    "      max_tokens=1500,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    return response[ \"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3368f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b1bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_segments(raw_segments, max_len=3500):\n",
    "    '''\n",
    "    Join paper segments (by section_type) up to max length\n",
    "    '''\n",
    "    \n",
    "    indeces_sections = [[0,1]]\n",
    "    \n",
    "    prev_title = raw_segments[2][-1]\n",
    "    i = 2\n",
    "    cur_section = []\n",
    "    while i < len(raw_segments):\n",
    "        cur_title = raw_segments[i][-1]\n",
    "        if cur_title == prev_title:\n",
    "            cur_section.append(i)\n",
    "        else:\n",
    "            indeces_sections.append(cur_section)\n",
    "            cur_section = [i]\n",
    "            prev_title = cur_title\n",
    "        i += 1\n",
    "    \n",
    "    if len(cur_section) > 0:\n",
    "        indeces_sections.append(cur_section)\n",
    "    \n",
    "    joined_segments = []\n",
    "    for sec in indeces_sections:\n",
    "        cur_text = ''\n",
    "        cur_split = []\n",
    "        \n",
    "        for idx in sec:\n",
    "            if len(cur_text + '\\n' + raw_segments[idx][1]) < max_len or len(cur_text) == 0:\n",
    "                cur_split.append({'id': raw_segments[idx][0],\n",
    "                                  'title': raw_segments[idx][-2], 'section_type': raw_segments[idx][-1]})\n",
    "                cur_text = cur_text + '\\n' + raw_segments[idx][1]\n",
    "                cur_text = cur_text.strip()\n",
    "            \n",
    "            else:\n",
    "                joined_segments.append((cur_text, cur_split))\n",
    "                cur_text = ''\n",
    "                cur_split = []\n",
    "        \n",
    "        if len(cur_text) > 0:\n",
    "            joined_segments.append((cur_text, cur_split))\n",
    "                \n",
    "    return joined_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0bd238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "500fa163",
   "metadata": {},
   "source": [
    "### Run in cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ddf682",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('segmented_papers.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2928b95d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe33552",
   "metadata": {},
   "outputs": [],
   "source": [
    "davinci_dialogues = [] # or from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5baf078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_papers = set([d['meta_paper']['paper_id'] for d in davinci_dialogues])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9944e34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 115/4490 [17:49<14:19:23, 11.79s/it]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(510, 5000)): # for subsample\n",
    "    if data[i]['paper_id'] in processed_papers:\n",
    "        continue\n",
    "        \n",
    "    processed_papers.add(data[i]['paper_id'])\n",
    "    \n",
    "    segmented_paper = join_segments(data[i]['segments'])\n",
    "    \n",
    "    #  select random segment\n",
    "    j = random.randint(0, len(segmented_paper) - 1)\n",
    "    random_segment = segmented_paper[j]\n",
    "    \n",
    "    # skip acknowledgements\n",
    "    if random_segment[1][-1]['section_type'].startswith('acknowledgement'):\n",
    "        continue\n",
    "    \n",
    "    if len(random_segment[0]) < 1000:\n",
    "        continue\n",
    "        \n",
    "    with open('logs/processed.txt', 'a') as f:\n",
    "        f.write(f'Processing {i}\\n')\n",
    "        \n",
    "    try:\n",
    "        result = davinci_complete(random_segment[0])\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    davinci_dialogues.append({\n",
    "        'text': random_segment[0],\n",
    "        'dialogue': result,\n",
    "        'meta_segments': random_segment[1],\n",
    "        'meta_paper': {'title': data[i]['title'], 'paper_id': data[i]['paper_id']},\n",
    "    })\n",
    "    \n",
    "    with open('davinci_dialogues.pkl', 'wb') as f:\n",
    "        pickle.dump(davinci_dialogues, f)\n",
    "        \n",
    "    with open('logs/processed.txt', 'a') as f:\n",
    "        f.write(f'Saved for {i}, segments {j}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621ec26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba5852c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'In this section, we describe our proposed MNRE framework in detail. The key motivation of MNRE is that, for each relational fact, the relation patterns in sentences of different languages should be substantially consistent, and MNRE can utilize the pattern consistency and complementarity among languages to achieve better results for relation extraction.\\nFormally, given two entities, their corresponding sentences in m different languages are defined as T = {S 1 , S 2 , . . . , S m }, where S j = {x 1 j , x 2 j , . . . , x n j j } corresponds to the sentence set in the jth language with n j sentences. Our model measures a score f (T, r) for each relation r, which is expected to be high when r is the valid one, otherwise low. The MNRE framework contains two main components:\\n1. Sentence Encoder. Given a sentence x and two target entities, we employ CNN to encode relation patterns in x into a distributed representation x. The sentence encoder can also be implemented with GRU (Cho et al., 2014) or LSTM (Hochreiter and Schmidhuber, 1997). In experiments, we find CNN can achieve a better trade-off between computational efficiency and performance effectiveness. Thus, in this paper, we focus on CNN as the sentence encoder.\\n2. Multi-lingual Attention. With all sentences in various languages encoded into distributed vector representations, we apply mono-lingual and cross-lingual attentions to capture those informative sentences with accurate relation patterns. MNRE further aggregates these sentence vectors with weighted attentions into global representations for relation prediction.\\nWe introduce the two components in detail as follows.\\nThe sentence encoder aims to transform a sentence x into its distributed representation x via CNN. First, it embeds the words in the input sentence into dense real-valued vectors. Next, it employs convolutional, max-pooling and non-linear transformation layers to construct the distributed representation of the sentence, i.e., x.\\nFollowing (Zeng et al., 2014), we transform each input word into the concatenation of two kinds of representations: (1) a word embedding which captures syntactic and semantic meanings of the word, and (2) a position embedding which specifies the position information of this word with respect to two target entities. In this way, we can represent the input sentence as a vector sequence w = {w 1 , w 2 , . . .} with w i ∈ R',\n",
       " 'dialogue': ' h , where h is the concatenation of word embedding and position embedding. \\n\\nSummary: The proposed MNRE framework contains two main components: a sentence encoder using CNN to encode relation patterns into distributed representations and a multi-lingual attention to capture informative sentences with accurate relation patterns.\\n\\nPerson: What exactly is the purpose of the sentence encoder?\\nYou: The sentence encoder is used to transform a sentence into a distributed representation via CNN by embedding words, applying convolutional, max-pooling and non-linear transformation layers.\\nPerson: What is the purpose of the multi-lingual attention?\\nYou: The multi-lingual attention is used to capture those sentences with accurate relation patterns by aggregating the sentence vectors with weighted attentions into global representations for relation prediction.\\nPerson: How does the sentence encoder encode relation patterns?\\nYou: The sentence encoder encodes relation patterns by transforming each input word into the concatenation of two kinds of representations: a word embedding to capture syntactic and semantic meanings of the word, and a position embedding to specify the position information of this word with respect to two target entities.\\nPerson: What kind of representations are used in the sentence encoder?\\nYou: The representations used in the sentence encoder are dense real-valued vectors, which are the concatenation of word embedding and position embedding.',\n",
       " 'meta_segments': [{'id': '672c8bf27fd6c04d34496e359844f1f9d95ed1e4_3',\n",
       "   'title': 'Methodology',\n",
       "   'section_type': 'methodology'},\n",
       "  {'id': '672c8bf27fd6c04d34496e359844f1f9d95ed1e4_4',\n",
       "   'title': 'Sentence Encoder',\n",
       "   'section_type': 'methodology'},\n",
       "  {'id': '672c8bf27fd6c04d34496e359844f1f9d95ed1e4_5',\n",
       "   'title': 'Input Representation',\n",
       "   'section_type': 'methodology'}],\n",
       " 'meta_paper': {'title': 'Neural Relation Extraction with Multi-lingual Attention',\n",
       "  'paper_id': '672c8bf27fd6c04d34496e359844f1f9d95ed1e4'}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out example\n",
    "davinci_dialogues[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c08fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824b562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f1a1cbe",
   "metadata": {},
   "source": [
    "### Postprocess constructed dialogues\n",
    "\n",
    "Parse dialogues into summary, person and bot utterances; remove special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc8db2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ddc03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('papers_segmented_data/davinci_dialogues_full_v2.pkl', 'rb') as f:\n",
    "    davinci_dialogues = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "256cbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_summary(text):\n",
    "    return 'summary:' in text.lower()\n",
    "\n",
    "\n",
    "def clear_parts(text, part_to_remove):\n",
    "    for s in part_to_remove:\n",
    "        text = text.replace(s, '')\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def postproc_davinci_dialogue(full_text_raw):\n",
    "    bot_parts = ['Me:', 'You:', 'Answer:']\n",
    "    person_parts = ['Person:', 'Other person:', 'Other:']\n",
    "    summary_parts = ['Summary:', 'summary:']\n",
    "    \n",
    "    if 'person 1' in full_text_raw.lower() and 'person 2' in full_text_raw.lower():\n",
    "        if re.search('person 1', full_text_raw.lower()).span()[0] < \\\n",
    "                    re.search('person 2', full_text_raw.lower()).span()[0]:\n",
    "            person_parts.append('Person 1:')\n",
    "            bot_parts.append('Person 2:')\n",
    "        else:\n",
    "            person_parts.append('Person 2:')\n",
    "            bot_parts.append('Person 1:')\n",
    "    elif 'person 2' in full_text_raw.lower():\n",
    "        person_parts.append('Person 2:')\n",
    "        \n",
    "    part_to_remove = bot_parts + person_parts + summary_parts\n",
    "    \n",
    "    for p in part_to_remove:\n",
    "        full_text_raw = re.sub(f'({p})' + r'\\s+(\\S)',  r'\\1 \\2', full_text_raw)\n",
    "    \n",
    "    items = [s for s in full_text_raw.strip().split('\\n') if len(s.strip()) > 0]\n",
    "    \n",
    "    dial_parsed = {}\n",
    "    \n",
    "    summ_idx = -1\n",
    "    for i in range(len(items)):\n",
    "        if check_summary(items[i]):\n",
    "            summ_idx = i\n",
    "            break\n",
    "    \n",
    "    if summ_idx == -1:\n",
    "        for i in range(len(items)):\n",
    "            is_person, is_bot = False, False\n",
    "            for part in person_parts:\n",
    "                if part.lower() in items[i].lower()[:10]:\n",
    "                    is_person = True\n",
    "            if is_person:\n",
    "                break\n",
    "            for part in bot_parts:\n",
    "                if part.lower() in items[i].lower()[:10]:\n",
    "                    summ_idx = i\n",
    "                    is_bot = True\n",
    "            if is_bot:\n",
    "                break\n",
    "    \n",
    "    if summ_idx >= 0:\n",
    "        dial_parsed['summary'] = clear_parts(items[summ_idx], part_to_remove)\n",
    "    else:\n",
    "        dial_parsed['summary'] = ''\n",
    "\n",
    "    dial_parsed['turns'] = []\n",
    "    \n",
    "    person_start = 0\n",
    "    correct_order = True\n",
    "    for j, utterance in enumerate(items[summ_idx+1:]):\n",
    "        speaker = ['person', 'bot'][(j + person_start) % 2]\n",
    "\n",
    "        for part in bot_parts:\n",
    "            if part.lower() in utterance.lower()[:10] and speaker == 'person':\n",
    "                speaker = 'bot'\n",
    "                correct_order = False\n",
    "                person_start += 1\n",
    "\n",
    "        for part in person_parts:\n",
    "            if part.lower() in utterance.lower()[:10] and speaker == 'bot':\n",
    "                speaker = 'person'\n",
    "                correct_order = False\n",
    "                person_start += 1\n",
    "\n",
    "        dial_parsed['turns'].append({'speaker': speaker, 'text': clear_parts(utterance, part_to_remove)})\n",
    "\n",
    "    dial_parsed['correct_order'] = correct_order\n",
    "    \n",
    "    return dial_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6125823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3588/3588 [00:00<00:00, 13280.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(davinci_dialogues))):\n",
    "    davinci_dialogues[i]['parsed_dialogue'] = postproc_davinci_dialogue(davinci_dialogues[i]['dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec7881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b5f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('davinci_dialogues_postproc.pkl', 'wb') as f:\n",
    "    pickle.dump(davinci_dialogues, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a98a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5886eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
